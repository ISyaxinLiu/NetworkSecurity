#!/usr/bin/env python3
"""
æµ‹è¯•Data Transformationç»„ä»¶
"""

import sys
import os
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

def test_data_transformation():
    """
    æµ‹è¯•Data Transformationå®Œæ•´æµç¨‹
    """
    try:
        print("ğŸ”„ å¼€å§‹æµ‹è¯•Data Transformationç»„ä»¶")
        print("=" * 60)
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from networksecurity.entity.config_entity import (
            TrainingPipelineConfig, 
            DataIngestionConfig, 
            DataValidationConfig,
            DataTransformationConfig
        )
        from networksecurity.components.data_ingestion import DataIngestion
        from networksecurity.components.data_validation import DataValidation
        from networksecurity.components.data_transformation import DataTransformation
        from networksecurity.exception.exception import NetworkSecurityException
        from networksecurity.logging.logger import logging
        
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æ­¥éª¤1: åˆ›å»ºé…ç½®å¯¹è±¡
        print("\nğŸ“‹ æ­¥éª¤1: åˆ›å»ºé…ç½®å¯¹è±¡")
        training_pipeline_config = TrainingPipelineConfig()
        data_ingestion_config = DataIngestionConfig(training_pipeline_config)
        data_validation_config = DataValidationConfig(training_pipeline_config)
        data_transformation_config = DataTransformationConfig(training_pipeline_config)
        
        print(f"   - æ•°æ®è½¬æ¢ç›®å½•: {data_transformation_config.data_transformation_dir}")
        print(f"   - è½¬æ¢è®­ç»ƒæ–‡ä»¶: {data_transformation_config.transformed_train_file_path}")
        print(f"   - è½¬æ¢æµ‹è¯•æ–‡ä»¶: {data_transformation_config.transformed_test_file_path}")
        print(f"   - é¢„å¤„ç†å™¨æ–‡ä»¶: {data_transformation_config.transformed_object_file_path}")
        
        # æ­¥éª¤2: æ‰§è¡Œæ•°æ®æ‘„å–
        print("\nğŸ“¥ æ­¥éª¤2: æ‰§è¡Œæ•°æ®æ‘„å–")
        data_ingestion = DataIngestion(data_ingestion_config)
        data_ingestion_artifact = data_ingestion.initiate_data_ingestion()
        print("âœ… æ•°æ®æ‘„å–å®Œæˆ")
        
        # æ­¥éª¤3: æ‰§è¡Œæ•°æ®éªŒè¯
        print("\nğŸ” æ­¥éª¤3: æ‰§è¡Œæ•°æ®éªŒè¯")
        data_validation = DataValidation(data_ingestion_artifact, data_validation_config)
        data_validation_artifact = data_validation.initiate_data_validation()
        
        if not data_validation_artifact.validation_status:
            raise Exception("æ•°æ®éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æ•°æ®è½¬æ¢")
        
        print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
        
        # æ­¥éª¤4: åˆ›å»ºæ•°æ®è½¬æ¢å¯¹è±¡
        print("\nğŸ”„ æ­¥éª¤4: åˆ›å»ºæ•°æ®è½¬æ¢å¯¹è±¡")
        data_transformation = DataTransformation(
            data_validation_artifact=data_validation_artifact,
            data_transformation_config=data_transformation_config
        )
        print("âœ… æ•°æ®è½¬æ¢å¯¹è±¡åˆ›å»ºæˆåŠŸ")
        
        # æ­¥éª¤5: æ‰§è¡Œæ•°æ®è½¬æ¢
        print("\nğŸš€ æ­¥éª¤5: æ‰§è¡Œæ•°æ®è½¬æ¢æµç¨‹")
        print("   è¿™å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        print("   1. è¯»å–éªŒè¯åçš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®")
        print("   2. åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡")
        print("   3. å°†ç›®æ ‡å˜é‡ä»[-1,1]è½¬æ¢ä¸º[0,1]")
        print("   4. ä½¿ç”¨KNN Imputerå¤„ç†ç¼ºå¤±å€¼")
        print("   5. ä¿å­˜è½¬æ¢åçš„æ•°æ®å’Œé¢„å¤„ç†å™¨")
        
        # å¼€å§‹è½¬æ¢
        data_transformation_artifact = data_transformation.initiate_data_transformation()
        
        print("âœ… æ•°æ®è½¬æ¢æµç¨‹å®Œæˆ!")
        
        # æ­¥éª¤6: éªŒè¯è½¬æ¢ç»“æœ
        print("\nğŸ“Š æ­¥éª¤6: éªŒè¯è½¬æ¢ç»“æœ")
        
        # æ£€æŸ¥è½¬æ¢åçš„è®­ç»ƒæ•°æ®
        if os.path.exists(data_transformation_artifact.transformed_train_file_path):
            train_arr = np.load(data_transformation_artifact.transformed_train_file_path)
            print(f"   âœ… è½¬æ¢åè®­ç»ƒæ•°æ®: {train_arr.shape}")
            print(f"      - ç‰¹å¾æ•°é‡: {train_arr.shape[1] - 1}")
            print(f"      - æ ·æœ¬æ•°é‡: {train_arr.shape[0]}")
            
            # æ£€æŸ¥ç›®æ ‡å˜é‡åˆ†å¸ƒ
            target_col = train_arr[:, -1]  # æœ€åä¸€åˆ—æ˜¯ç›®æ ‡å˜é‡
            unique_values, counts = np.unique(target_col, return_counts=True)
            print(f"      - ç›®æ ‡å˜é‡åˆ†å¸ƒ: {dict(zip(unique_values, counts))}")
        else:
            print("   âŒ è½¬æ¢åè®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥è½¬æ¢åçš„æµ‹è¯•æ•°æ®
        if os.path.exists(data_transformation_artifact.transformed_test_file_path):
            test_arr = np.load(data_transformation_artifact.transformed_test_file_path)
            print(f"   âœ… è½¬æ¢åæµ‹è¯•æ•°æ®: {test_arr.shape}")
            print(f"      - ç‰¹å¾æ•°é‡: {test_arr.shape[1] - 1}")
            print(f"      - æ ·æœ¬æ•°é‡: {test_arr.shape[0]}")
            
            # æ£€æŸ¥ç›®æ ‡å˜é‡åˆ†å¸ƒ
            target_col = test_arr[:, -1]
            unique_values, counts = np.unique(target_col, return_counts=True)
            print(f"      - ç›®æ ‡å˜é‡åˆ†å¸ƒ: {dict(zip(unique_values, counts))}")
        else:
            print("   âŒ è½¬æ¢åæµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥é¢„å¤„ç†å™¨å¯¹è±¡
        if os.path.exists(data_transformation_artifact.transformed_object_file_path):
            print(f"   âœ… é¢„å¤„ç†å™¨å·²ä¿å­˜: {data_transformation_artifact.transformed_object_file_path}")
            
            # å°è¯•åŠ è½½é¢„å¤„ç†å™¨
            from networksecurity.utils.main_utils.utils import load_object
            try:
                preprocessor = load_object(data_transformation_artifact.transformed_object_file_path)
                print(f"      - é¢„å¤„ç†å™¨ç±»å‹: {type(preprocessor)}")
                if hasattr(preprocessor, 'steps'):
                    print(f"      - ç®¡é“æ­¥éª¤: {[step[0] for step in preprocessor.steps]}")
            except Exception as e:
                print(f"      - é¢„å¤„ç†å™¨åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}")
        else:
            print("   âŒ é¢„å¤„ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥final_modelç›®å½•
        final_preprocessor_path = "final_model/preprocessor.pkl"
        if os.path.exists(final_preprocessor_path):
            print(f"   âœ… Final modelé¢„å¤„ç†å™¨å·²ä¿å­˜: {final_preprocessor_path}")
        else:
            print("   âŒ Final modelé¢„å¤„ç†å™¨ä¸å­˜åœ¨")
        
        # æ­¥éª¤7: æ•°æ®è´¨é‡æ£€æŸ¥
        print("\nğŸ” æ­¥éª¤7: æ•°æ®è´¨é‡æ£€æŸ¥")
        
        if 'train_arr' in locals() and 'test_arr' in locals():
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
            train_nan_count = np.isnan(train_arr).sum()
            test_nan_count = np.isnan(test_arr).sum()
            
            print(f"   - è®­ç»ƒæ•°æ®ç¼ºå¤±å€¼: {train_nan_count}")
            print(f"   - æµ‹è¯•æ•°æ®ç¼ºå¤±å€¼: {test_nan_count}")
            
            if train_nan_count == 0 and test_nan_count == 0:
                print("   âœ… æ²¡æœ‰ç¼ºå¤±å€¼ï¼ŒKNN Imputerå·¥ä½œæ­£å¸¸")
            else:
                print("   âš ï¸ ä»å­˜åœ¨ç¼ºå¤±å€¼ï¼Œéœ€è¦æ£€æŸ¥")
            
            # æ£€æŸ¥æ•°æ®èŒƒå›´
            print(f"   - è®­ç»ƒæ•°æ®èŒƒå›´: [{train_arr.min():.3f}, {train_arr.max():.3f}]")
            print(f"   - æµ‹è¯•æ•°æ®èŒƒå›´: [{test_arr.min():.3f}, {test_arr.max():.3f}]")
            
            # æ£€æŸ¥ç›®æ ‡å˜é‡æ˜¯å¦æ­£ç¡®è½¬æ¢
            train_target = train_arr[:, -1]
            test_target = test_arr[:, -1]
            
            if set(np.unique(train_target)).issubset({0, 1}) and set(np.unique(test_target)).issubset({0, 1}):
                print("   âœ… ç›®æ ‡å˜é‡æˆåŠŸè½¬æ¢ä¸º[0,1]æ ¼å¼")
            else:
                print("   âŒ ç›®æ ‡å˜é‡è½¬æ¢å¯èƒ½æœ‰é—®é¢˜")
        
        # æ­¥éª¤8: æ€»ç»“
        print("\nğŸ‰ æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        print("âœ… Data Transformationç»„ä»¶æµ‹è¯•æˆåŠŸ!")
        print("âœ… æ•°æ®è½¬æ¢æµç¨‹æ­£å¸¸å·¥ä½œ")
        print("âœ… KNN Imputeræ­£ç¡®å¤„ç†ç¼ºå¤±å€¼")
        print("âœ… ç›®æ ‡å˜é‡æˆåŠŸè½¬æ¢")
        print("âœ… é¢„å¤„ç†å™¨æ­£ç¡®ä¿å­˜")
        
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   - è½¬æ¢åè®­ç»ƒæ•°æ®: {data_transformation_artifact.transformed_train_file_path}")
        print(f"   - è½¬æ¢åæµ‹è¯•æ•°æ®: {data_transformation_artifact.transformed_test_file_path}")
        print(f"   - é¢„å¤„ç†å™¨å¯¹è±¡: {data_transformation_artifact.transformed_object_file_path}")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("   æ•°æ®è½¬æ¢å®Œæˆï¼Œå¯ä»¥ç»§ç»­è¿›è¡Œæ¨¡å‹è®­ç»ƒ (Model Training)")
        
        return data_transformation_artifact
        
    except NetworkSecurityException as nse:
        print(f"\nâŒ ç½‘ç»œå®‰å…¨å¼‚å¸¸: {str(nse)}")
        return None
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        return None

def test_transformer_object():
    """
    å•ç‹¬æµ‹è¯•é¢„å¤„ç†å™¨å¯¹è±¡
    """
    try:
        print("\nğŸ§ª æµ‹è¯•é¢„å¤„ç†å™¨å¯¹è±¡")
        print("-" * 40)
        
        from networksecurity.components.data_transformation import DataTransformation
        import pandas as pd
        import numpy as np
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        np.random.seed(42)
        test_data = pd.DataFrame({
            'feature1': np.random.randn(100),
            'feature2': np.random.randn(100),
            'feature3': np.random.randn(100)
        })
        
        # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
        test_data.loc[0:5, 'feature1'] = np.nan
        test_data.loc[10:15, 'feature2'] = np.nan
        
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
        print(f"ç¼ºå¤±å€¼æ•°é‡: {test_data.isnull().sum().sum()}")
        
        # è·å–é¢„å¤„ç†å™¨
        preprocessor = DataTransformation.get_data_transformer_object()
        print(f"é¢„å¤„ç†å™¨ç±»å‹: {type(preprocessor)}")
        
        # è®­ç»ƒå¹¶è½¬æ¢
        preprocessor_fitted = preprocessor.fit(test_data)
        transformed_data = preprocessor_fitted.transform(test_data)
        
        print(f"è½¬æ¢åæ•°æ®å½¢çŠ¶: {transformed_data.shape}")
        print(f"è½¬æ¢åç¼ºå¤±å€¼: {np.isnan(transformed_data).sum()}")
        
        if np.isnan(transformed_data).sum() == 0:
            print("âœ… é¢„å¤„ç†å™¨æ­£ç¡®å¤„ç†äº†ç¼ºå¤±å€¼")
        else:
            print("âŒ é¢„å¤„ç†å™¨æœªèƒ½å®Œå…¨å¤„ç†ç¼ºå¤±å€¼")
        
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("Data Transformation ç»„ä»¶æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é¢„å¤„ç†å™¨å¯¹è±¡
    test_transformer_object()
    
    # å®Œæ•´æµç¨‹æµ‹è¯•
    artifact = test_data_transformation()
    
    if artifact:
        print("\nğŸŠ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("ğŸš€ Data Transformationç»„ä»¶å·²å‡†å¤‡å°±ç»ª!")
        print("ğŸ“Š ç°åœ¨å¯ä»¥ä½¿ç”¨è½¬æ¢åçš„æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒäº†!")
        return True
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)